{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modified Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---get image data - variable and label...#\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      " 144 123  23   0   0   0   0  12  10   0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---see what the variable looks like---#\n",
    "print(y_train[0])  #---this is the label---#\n",
    "\n",
    "print(x_train[0][5][22])   #--0 = sample number, 5=row, 22=column; pixel value = 247 in RGB scale upto 255---#\n",
    "print(x_train[0][5])       #--0 = sample number, 5=row; array of pixel values of all 28 columns of sample 0 row 5\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[9 0 0 ... 3 0 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "y_train[48909]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape((60000,28 * 28))  #---reshape the 3D tensor to 2D array of 60K samples and 784 features---#\n",
    "x_train = x_train.astype(\"float32\") / 255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape((10000,28 * 28))  #---reshape the 3D tensor to 2D array of 60K samples and 784 features---#\n",
    "x_test = x_test.astype(\"float32\") / 255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28,28]),\n",
    "#                                 keras.layers.Dense(300,activation='relu'),\n",
    "#                                 keras.layers.Dense(100,activation='relu'),\n",
    "#                                 keras.layers.Dense(10,activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(300,activation='relu',input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(100,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x1f26a6ff988>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f26a6ff948>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f211726348>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1=model.layers[0]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04092249, -0.0548816 ,  0.07130978,  0.04008415, -0.05455458,\n",
       "       -0.00226321,  0.05416594, -0.06696462,  0.01693781, -0.00753151,\n",
       "       -0.02344143, -0.01229712, -0.01378611,  0.03981893, -0.00993446,\n",
       "        0.01709858, -0.05450834,  0.03145903,  0.03018674, -0.01805964,\n",
       "       -0.05127047, -0.05805083, -0.04782791, -0.04613261, -0.01548999,\n",
       "        0.00568784,  0.00185822, -0.05999139, -0.05533024, -0.02760353,\n",
       "        0.05626614,  0.04979292, -0.01868046,  0.05237697, -0.03254284,\n",
       "       -0.01693688, -0.07135554, -0.01008242, -0.02153138,  0.0611559 ,\n",
       "       -0.00091128,  0.05916552, -0.0031506 , -0.07027016,  0.07006308,\n",
       "        0.00924678, -0.03589359,  0.0123817 , -0.04677603,  0.03934338,\n",
       "       -0.01383954, -0.04768261, -0.03565796,  0.03655922, -0.03022117,\n",
       "        0.05809914, -0.00945323, -0.00986033,  0.01073603, -0.06530429,\n",
       "       -0.03062419, -0.03558405, -0.03361536, -0.07056729,  0.00376553,\n",
       "        0.01853586,  0.01657381,  0.06355205,  0.03844856,  0.05355334,\n",
       "        0.06190798,  0.06917317, -0.05248592, -0.03063705, -0.07187334,\n",
       "       -0.07203788,  0.02556232, -0.01493231,  0.00275226, -0.01971786,\n",
       "       -0.06694774,  0.04456446, -0.00396761, -0.02334529, -0.05131581,\n",
       "        0.0193835 ,  0.06017777, -0.02130939, -0.06221084, -0.03516028,\n",
       "        0.0527247 , -0.06545001,  0.01780418,  0.02595795, -0.03665093,\n",
       "        0.06178832, -0.0431328 ,  0.05473344, -0.06288296, -0.02037824,\n",
       "        0.04222491,  0.03966816, -0.05499772, -0.06633399, -0.01538675,\n",
       "        0.01453272, -0.01880514, -0.05616571,  0.06036015,  0.03167245,\n",
       "       -0.03944363,  0.07144439, -0.00030006, -0.01121315, -0.02739769,\n",
       "       -0.0322393 ,  0.03466599, -0.05464451,  0.01266649, -0.01836907,\n",
       "        0.03105634,  0.05899601,  0.04196513, -0.03904723, -0.04217044,\n",
       "       -0.0711888 , -0.024452  , -0.04681733,  0.0577147 , -0.03084061,\n",
       "        0.03126226, -0.06704146, -0.05288445, -0.01992447, -0.06818997,\n",
       "       -0.01685167, -0.05944317, -0.05856784, -0.03501059,  0.06496082,\n",
       "        0.03018023,  0.02627905, -0.06612817,  0.03128587,  0.01810528,\n",
       "       -0.02427246,  0.01270822,  0.03803171,  0.04088239, -0.03906869,\n",
       "        0.06896104, -0.05880991,  0.06326024,  0.0589049 ,  0.05829731,\n",
       "       -0.0100776 ,  0.04877897, -0.01179224, -0.03597148, -0.05248186,\n",
       "       -0.05446874, -0.00444195,  0.02396309, -0.0100449 , -0.01663124,\n",
       "       -0.04897248, -0.03476362,  0.06288232, -0.02157675,  0.05363719,\n",
       "       -0.01784579,  0.00908577,  0.03796663, -0.02030842, -0.06191112,\n",
       "       -0.05576129,  0.07344846,  0.04142325, -0.03777397, -0.00712663,\n",
       "        0.01482248,  0.01331935,  0.06768849,  0.01665416, -0.07390225,\n",
       "        0.05930525,  0.0494743 ,  0.03112903, -0.07074768,  0.01963185,\n",
       "        0.01502437, -0.04627093, -0.01530319,  0.04482732, -0.0489491 ,\n",
       "        0.06644829, -0.0333198 ,  0.07163271,  0.03751899,  0.06243037,\n",
       "        0.01137947, -0.03121421,  0.03026245, -0.04007891,  0.01538083,\n",
       "       -0.01820803,  0.02035268,  0.01441511,  0.05791305, -0.06792732,\n",
       "       -0.02382211,  0.00047372, -0.00220421,  0.02902582, -0.00670927,\n",
       "        0.05442944, -0.00315844, -0.05544032,  0.00679509, -0.04464325,\n",
       "        0.00029007, -0.00585092,  0.07286814,  0.04994013, -0.00736547,\n",
       "        0.04578301, -0.04106755,  0.04065839, -0.01844503, -0.03833892,\n",
       "       -0.04994554, -0.04937523,  0.04496266, -0.03890069, -0.04978915,\n",
       "       -0.0106499 ,  0.04898775,  0.01075897, -0.00151393, -0.02031947,\n",
       "        0.00869203, -0.02572287, -0.04325715, -0.02633353,  0.02520038,\n",
       "        0.02220897,  0.06807181, -0.01478796,  0.03858512,  0.05275393,\n",
       "        0.02568759,  0.02275752, -0.07360688,  0.03970477,  0.06141716,\n",
       "        0.05111536, -0.00551374,  0.0261677 , -0.01318325, -0.01810187,\n",
       "        0.0741134 ,  0.02163608,  0.0043054 ,  0.02156671,  0.07350598,\n",
       "        0.0367735 ,  0.0138886 ,  0.01499285,  0.04581982, -0.05401425,\n",
       "        0.05369094,  0.0049346 , -0.04697177, -0.01814288,  0.06126894,\n",
       "        0.00492917, -0.01592478,  0.02825995,  0.05057548, -0.07280557,\n",
       "       -0.0451308 , -0.01260519,  0.04350145,  0.04654618, -0.05832158,\n",
       "       -0.02909822, -0.07158101,  0.04818809,  0.00772332, -0.054465  ,\n",
       "        0.03647733, -0.03209099,  0.06452391,  0.02692682, -0.05884283,\n",
       "        0.01791561, -0.06104257, -0.06307948, -0.06621739, -0.04815464],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Sparse categorical crossentropy loss function is used because the label data is NOT one-hot encoded----#\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "235/235 [==============================] - 2s 4ms/step - loss: 0.8632 - accuracy: 0.7030\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4336 - accuracy: 0.8409\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3678 - accuracy: 0.8657\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8765\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3071 - accuracy: 0.8849\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.8944\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.8996\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2606 - accuracy: 0.9022\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9093\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2402 - accuracy: 0.9081\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.9127\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9165\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2158 - accuracy: 0.9181\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9239\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9255\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9287\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9291\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.9351\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.9344\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1621 - accuracy: 0.9390\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1617 - accuracy: 0.9374\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9390\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1484 - accuracy: 0.9435\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1416 - accuracy: 0.9449\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1380 - accuracy: 0.9489\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9481\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9503\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9505\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f26ab89208>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=30,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8939\n",
      "test accuracy = 0.89\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test)\n",
    "print('test accuracy = %0.2f' %test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
